{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b27413ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device Name: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "CUDA Version: 12.6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device Name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA Version:\", torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d972e25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv('../dataset/icml_face_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ffe8cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "id = 45 \n",
    "label = int(data.iloc[id]['emotion'])\n",
    "pixel_seq = data.iloc[id, 2]\n",
    "image = np.fromstring(pixel_seq, sep=' ', dtype=np.uint8).reshape(48, 48)\n",
    "\n",
    "plt.imshow(image, cmap='gray')  # Show as grayscale\n",
    "plt.title(f'Emotion label: {label}')\n",
    "plt.axis('off')  # Hide axis ticks\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43b9e7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")  # or \".\" depending on notebook location\n",
    "\n",
    "import yaml \n",
    "\n",
    "with open(\"../cfgs/cnn_fer.yaml\",\"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d07b1f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Image batch shape: torch.Size([1, 1, 48, 48])\n",
      "✅ Labels shape: torch.Size([1])\n",
      "✅ Unique labels in batch: tensor([3])\n"
     ]
    }
   ],
   "source": [
    "from utils.dataset import DataModule\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# Define any transform (optional)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "#cfg = cnn_fer.cfg\n",
    "# Extract data config\n",
    "data_cfg = cfg['data_args']\n",
    "\n",
    "# Initialize data module\n",
    "dm = DataModule(\n",
    "    path=data_cfg['path'],\n",
    "    transform=transform,\n",
    "    batch_size=data_cfg['batch_size'],\n",
    "    num_workers=data_cfg['num_workers'],\n",
    "    shuffle=True,\n",
    "    pin_memory=data_cfg['pin_memory']\n",
    ")\n",
    "\n",
    "# Get train loader\n",
    "train_loader = dm.get_train_loader()\n",
    "\n",
    "# Fetch one batch and inspect\n",
    "for labels, images in train_loader:\n",
    "    print(f\"✅ Image batch shape: {images.shape}\")   # Expected: (64, 1, 48, 48)\n",
    "    print(f\"✅ Labels shape: {labels.shape}\")         # Expected: (64,)\n",
    "    print(f\"✅ Unique labels in batch: {labels.unique()}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bec28c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")  # or \".\" depending on notebook location\n",
    "\n",
    "import yaml \n",
    "from utils.dataset import DataModule\n",
    "from torchvision import transforms\n",
    "\n",
    "with open(\"../cfgs/cnn_fer.yaml\",\"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "data_cfg = cfg['data_args']\n",
    "dm = DataModule(\n",
    "    path=data_cfg['path'],\n",
    "    transform=None,\n",
    "    batch_size=data_cfg['batch_size'],\n",
    "    num_workers=data_cfg['num_workers'],\n",
    "    shuffle=True,\n",
    "    pin_memory=data_cfg['pin_memory']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e56767ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.convnetfer_model import ConvNetFer\n",
    "import torch.nn as nn\n",
    "\n",
    "# cfg['model_args']['activation'] = eval( cfg['model_args']['activation'])  # e.g., 'nn.ReLU' → nn.ReLU\n",
    "# cfg['model_args']['norm_layer'] = eval(cfg['model_args']['norm_layer'])\n",
    "#model = eval(cfg['model_name'])(**cfg['model_args'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "369a226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dm.get_train_loader()\n",
    "eval_loader = dm.get_val_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92e632cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainers.cnn_trainer import CNNTrainer\n",
    "\n",
    "cnn_trainer = CNNTrainer(config = cfg, log_dir='../log/',train_loader=train_loader,eval_loader=eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6308872e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNetFer(\n",
       "  (layers): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.3, inplace=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): ReLU()\n",
       "    (9): Dropout(p=0.3, inplace=False)\n",
       "    (10): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU()\n",
       "    (13): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=9216, out_features=100, bias=True)\n",
       "    (1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Linear(in_features=100, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aad8f8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/28709 [00:38<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcnn_trainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/dior00002/HLCV/project/notebooks/../trainers/base_trainer.py:45\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28mself\u001b[39m.logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     44\u001b[39m \u001b[38;5;28mself\u001b[39m.current_epoch = epoch\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m train_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m log = {\u001b[33m\"\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m\"\u001b[39m:epoch}\n\u001b[32m     47\u001b[39m log.update(train_results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/dior00002/HLCV/project/notebooks/../trainers/cnn_trainer.py:50\u001b[39m, in \u001b[36mCNNTrainer._train_epoch\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     48\u001b[39m labels = labels.to(\u001b[38;5;28mself\u001b[39m._device)\n\u001b[32m     49\u001b[39m images = images.to(\u001b[38;5;28mself\u001b[39m._device)\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m loss = \u001b[38;5;28mself\u001b[39m.criterion(outputs, labels)\n\u001b[32m     52\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/dior00002/HLCV/project/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/dior00002/HLCV/project/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/dior00002/HLCV/project/notebooks/../models/convnetfer_model.py:67\u001b[39m, in \u001b[36mConvNetFer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     out = out.view(out.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m)\n\u001b[32m     69\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.classifier(out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/dior00002/HLCV/project/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/dior00002/HLCV/project/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/dior00002/HLCV/project/venv/lib/python3.11/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/dior00002/HLCV/project/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/dior00002/HLCV/project/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/dior00002/HLCV/project/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193\u001b[39m, in \u001b[36m_BatchNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    186\u001b[39m     bn_training = (\u001b[38;5;28mself\u001b[39m.running_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.running_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    188\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[33;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[33;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[33;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunning_mean\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/dior00002/HLCV/project/venv/lib/python3.11/site-packages/torch/nn/functional.py:2822\u001b[39m, in \u001b[36mbatch_norm\u001b[39m\u001b[34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[39m\n\u001b[32m   2819\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[32m   2820\u001b[39m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m.size())\n\u001b[32m-> \u001b[39m\u001b[32m2822\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2823\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2824\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2825\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2826\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2827\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2828\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2829\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2830\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2831\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcudnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2832\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "cnn_trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
